# -*- coding: utf-8 -*-
"""LVADSUSR116_Shreyas_Final_assesment_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16tiwITyNGVpUvuoXbodg8sQqMdsdoZRS
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, f1_score, recall_score, confusion_matrix, silhouette_score, davies_bouldin_score, calinski_harabasz_score, classification_report
import time
from sklearn.preprocessing import LabelEncoder, MinMaxScaler,StandardScaler
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.cluster import KMeans

df = pd.read_csv('loan_approval.csv')

df.head()

df.isna().sum()
# No null values

df[df.duplicated()]
# No duplicates

df.columns = df.columns.str.strip()



df1 = df.select_dtypes(include = ['int','float'])

# Outliers
dicti = {}

for i in df1.columns:


    Q1 = df1[i].quantile(0.25)
    Q3 = df1[i].quantile(0.75)
    IQR = Q3 - Q1

    lower_limit = Q1 - (1.5*IQR)
    upper_limit = Q3 + (1.5*IQR)

    dicti[i] = df1[(df1[i] < lower_limit) | (df1[i] > upper_limit)].count()[0]

dicti
# this shows how many outliers are there in each column



# considering we have close to 4.3k rows, we can go ahead and remove the outliers

Q1 = df['residential_assets_value'].quantile(0.25)
Q3 = df['residential_assets_value'].quantile(0.75)
IQR = Q3 - Q1

lower_limit = Q1 - (1.5*IQR)
upper_limit = Q3 + (1.5*IQR)

df = df[~((df['residential_assets_value'] < lower_limit) | (df['residential_assets_value'] > upper_limit))]

Q1 = df['commercial_assets_value'].quantile(0.25)
Q3 = df['commercial_assets_value'].quantile(0.75)
IQR = Q3 - Q1

lower_limit = Q1 - (1.5*IQR)
upper_limit = Q3 + (1.5*IQR)

df = df[~((df['commercial_assets_value'] < lower_limit) | (df['commercial_assets_value'] > upper_limit))]



# descriptive stats
df.describe()

df.head()

sns.boxplot(data = df, x = 'education', y = 'income_annum', hue = 'loan_status')

sns.scatterplot(data = df, x = 'income_annum', y = 'loan_amount')



df.shape

df.info()

df['loan_status'] = df['loan_status'].str.strip()

def loan_status(loan_status):
    if loan_status == 'Approved':
        return 1
    else:
        return 0

df['loan_status'] = df.apply(lambda x: loan_status(x['loan_status']), axis = 1)



df['loan_status'].unique()

df3 = df.corr(numeric_only = True)['loan_status'].to_frame()
df3



df.drop('loan_id', axis = 1, inplace = True)

df1 = pd.get_dummies(data = df, columns = ['education','self_employed'], dtype = 'int')

df1



X = df1.drop('loan_status', axis = 1)
y = df1['loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)

rf_classifier = RandomForestClassifier(n_estimators = 128,max_features = 'log2')

rf_classifier.fit(X_train,y_train)

y_pred = rf_classifier.predict(X_test)

print(classification_report(y_test,y_pred))

accuracy_score(y_test,y_pred)

sns.heatmap(data = confusion_matrix(y_test,y_pred), annot = True)

